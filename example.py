# -------------------------------------------------------------
# Example of how to use the data generator provided by Jessica
# Sena to generate samples from the benchmark "Human Activity
# Recognition Based on Wearable Sensor Data: A Standardization
# of the State-of-the-Art"
#
# (C) 2020 JÃ©ssica Sena, Brazil
# Released under GNU Public License (GPL)
# email jessicasenasouza@gmail.com
# -------------------------------------------------------------

import sys
import numpy as np
import random
from sklearn.metrics.classification import accuracy_score, recall_score, f1_score
import scipy.stats as st
from sensordata_generator import DataGenerator
import keras
import pickle

keras.backend.set_image_data_format('channels_first')


def custom_model(shape, n_classes):
    """Dummy CNN model to classify sensor-based human activities"""

    activation = 'relu'
    inp = keras.layers.Input((shape[1], shape[2], shape[3]))
    H = keras.layers.Conv2D(filters=16, kernel_size=(5, 1))(inp)
    H = keras.layers.Activation(activation)(H)
    H = keras.layers.MaxPooling2D(pool_size=(2, 1))(H)

    H = keras.layers.Conv2D(filters=32, kernel_size=(5, 1))(H)
    H = keras.layers.Activation(activation)(H)
    H = keras.layers.MaxPooling2D(pool_size=(2, 1))(H)

    H = keras.layers.Flatten()(H)
    H = keras.layers.Dense(n_classes)(H)
    H = keras.layers.Activation('softmax')(H)

    model = keras.models.Model([inp], H)

    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adadelta')

    return model


if __name__ == '__main__':
    np.random.seed(12227)

    # Just some variables that we will need in this example :)
    dataset_fold = 'Z:/Datasets/LOSO/uncrompressed_datasets/UTD-MHAD1_1s'
    batch_size = 32
    n_epochs = 50
    avg_acc = []
    avg_recall = []
    avg_f1 = []

    # Loading the information regarding the dataset
    # These two files are generated by npz_to_fold.py
    # as well as the samples read by the DataGenerator
    folds = np.load(dataset_fold + "/folds.npy", allow_pickle=True)
    labels = pickle.load(open(dataset_fold + "/labels.pkl", "rb"))

    for i in range(0, len(folds)):
        train_idx = folds[i][0]
        test_idx = folds[i][1]

        # Creates generator objects. Is important to set the batch size of the testing
        # generator to 1 or by a number divisible by the number of test samples.
        # Otherwise, the generator will return fewer samples than expected.
        training_generator = DataGenerator(dataset_fold, train_idx, labels, batch_size, shuffle=True)
        validation_generator = DataGenerator(dataset_fold, train_idx, labels, batch_size, shuffle=True)
        testing_generator = DataGenerator(dataset_fold, test_idx, labels, 1, shuffle=False)

        # Here some useful functions to get shape and n_classes information
        n_classes = training_generator.get_nclasses()
        shape = training_generator.get_shape()

        # Building a dummy CNN to classify the data
        model = custom_model(shape, n_classes)

        # Model fit using Keras generator
        model.fit_generator(generator=training_generator,
                            epochs=n_epochs,
                            use_multiprocessing=False,
                            workers=1,
                            verbose=0,
                            steps_per_epoch=int(np.floor(len(train_idx) / batch_size)),
                            validation_data=validation_generator,
                            validation_steps=int(np.floor(len(train_idx) / batch_size)))

        # Model predict using Keras generator
        y_pred = model.predict_generator(testing_generator)

        # Evaluation proposed by Artur et al. in the benchmark
        y_pred = np.argmax(y_pred, axis=1)
        y_true = np.argmax([labels[key] for key in test_idx], axis=1)

        acc_fold = accuracy_score(y_true, y_pred)
        avg_acc.append(acc_fold)

        recall_fold = recall_score(y_true, y_pred, average='macro')
        avg_recall.append(recall_fold)

        f1_fold = f1_score(y_true, y_pred, average='macro')
        avg_f1.append(f1_fold)

        print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold, i))
        print('______________________________________________________')
        del model

    ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))
    ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))
    ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))
    print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))
    print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))
    print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))
